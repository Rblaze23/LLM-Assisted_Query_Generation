# LLM-Assisted Query Generation and Exploration for NoSQL Databases

## Project Overview

This project implements a natural language interface for multiple NoSQL database types, allowing users to interact with Redis, MongoDB, HBase, Neo4j, and RDF stores using natural language queries. The system leverages Large Language Models (LLMs) and Model Context Protocol (MCP) to translate user queries into appropriate database-specific query languages.

## Project Objectives

1. **Natural Language Query Translation**
   - Users write queries in natural language
   - System uses LLM to generate queries in the corresponding NoSQL query language
   - Support for: Redis, MongoDB, HBase, Neo4j, RDF stores

2. **Database Schema and Metadata Exploration**
   - Users can request metadata and schema-like information for each database
   - Provide context to LLM for better query generation

3. **Query Validation and Explanation**
   - Validate queries generated by the LLM
   - Provide explanations about how queries map to database schema
   - Syntax and semantic checking

4. **Cross-Database Comparison**
   - Compare how the same natural language query is expressed across multiple NoSQL database types
   - Highlight differences in query syntax and approach

5. **Research Component**
   - Literature review of text-to-query systems
   - Evaluation and benchmarking against existing approaches

## Architecture: LLM Application + Multiple MCP Servers

### High-Level Architecture

```
┌─────────────────────────────────────────────────────────────┐
│              Main Application (Python/Node)                  │
│                                                              │
│  ┌────────────────────────────────────────────────────┐    │
│  │         Query Translation Engine (LLM)             │    │
│  │  • Takes natural language query                    │    │
│  │  • Decides which MCP server(s) to call            │    │
│  │  • Generates database-specific queries            │    │
│  └────────────────────────────────────────────────────┘    │
│                                                              │
│  ┌────────────────────────────────────────────────────┐    │
│  │         MCP Client Manager                         │    │
│  │  • Connects to multiple MCP servers               │    │
│  │  • Routes tool calls                              │    │
│  │  • Aggregates responses                           │    │
│  └────────────────────────────────────────────────────┘    │
└─────────────┬───────────────────────────────────────────────┘
              │ MCP Protocol
┌─────────────┴───────────────────────────────────────────────┐
│                   MCP Servers Layer                          │
│                                                              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐     │
│  │ mongodb-mcp  │  │  neo4j-mcp   │  │  redis-mcp   │     │
│  │              │  │              │  │              │     │
│  │ Tools:       │  │ Tools:       │  │ Tools:       │     │
│  │ • list_dbs   │  │ • get_labels │  │ • list_keys  │     │
│  │ • get_schema │  │ • get_rels   │  │ • get_type   │     │
│  │ • run_query  │  │ • run_cypher │  │ • execute    │     │
│  │ • validate   │  │ • explain    │  │ • info       │     │
│  │              │  │              │  │              │     │
│  │ Resources:   │  │ Resources:   │  │ Resources:   │     │
│  │ • collections│  │ • schema     │  │ • config     │     │
│  │ • sample_docs│  │ • graph_viz  │  │ • stats      │     │
│  └──────────────┘  └──────────────┘  └──────────────┘     │
│                                                              │
│  ┌──────────────┐  ┌──────────────┐                        │
│  │  hbase-mcp   │  │   rdf-mcp    │                        │
│  │              │  │              │                        │
│  │ Tools:       │  │ Tools:       │                        │
│  │ • describe   │  │ • list_graphs│                        │
│  │ • scan       │  │ • run_sparql │                        │
│  │ • execute    │  │ • validate   │                        │
│  └──────────────┘  └──────────────┘                        │
└─────────────────────────────────────────────────────────────┘
```

### Architecture Components

#### 1. Main Application Layer
- **Purpose**: Orchestrates the entire query translation pipeline
- **Responsibilities**:
  - Accept natural language input from users
  - Manage LLM interactions
  - Coordinate with multiple MCP servers
  - Aggregate and present results
  - Handle cross-database comparisons

#### 2. Query Translation Engine
- **Technology**: Groq API (for free)
- **Functions**:
  - Understand user intent from natural language
  - Determine target database(s)
  - Generate database-specific queries using context from MCP servers
  - Explain generated queries to users

#### 3. MCP Client Manager
- **Technology**: MCP Python Client
- **Functions**:
  - Establish connections to multiple MCP servers simultaneously
  - Route tool calls to appropriate servers
  - Handle async communication
  - Aggregate responses from multiple servers
  - Manage server lifecycle

#### 4. MCP Servers (Database-Specific)
Each MCP server is a standalone process that:
- Connects to its specific database type
- Exposes database operations as MCP tools
- Provides schema/metadata as MCP resources
- Handles query execution and validation

### MCP Server Specifications

#### MongoDB MCP Server

**Tools:**
- `list_databases()` - List all databases
- `list_collections(database: str)` - List collections in a database
- `get_collection_schema(database: str, collection: str)` - Infer schema from sample documents
- `execute_query(database: str, collection: str, query: str)` - Execute MongoDB query (JSON)
- `validate_query(database: str, collection: str, query: str)` - Validate without executing
- `get_indexes(database: str, collection: str)` - Get collection indexes
- `aggregate(database: str, collection: str, pipeline: str)` - Run aggregation pipeline

**Resources:**
- `mongodb://{database}/{collection}/schema` - Collection schema
- `mongodb://{database}/{collection}/samples` - Sample documents
- `mongodb://{database}/{collection}/indexes` - Index information

**Connection**: MongoDB driver (pymongo)

#### Neo4j MCP Server

**Tools:**
- `get_node_labels()` - Get all node labels
- `get_relationship_types()` - Get all relationship types
- `get_schema()` - Get complete graph schema
- `run_cypher(query: str)` - Execute Cypher query
- `explain_cypher(query: str)` - Get query execution plan
- `validate_cypher(query: str)` - Validate Cypher syntax
- `get_node_properties(label: str)` - Get properties for a node label
- `get_relationship_properties(type: str)` - Get properties for relationship type

**Resources:**
- `neo4j://schema` - Graph schema visualization
- `neo4j://labels` - All node labels
- `neo4j://relationships` - All relationship types
- `neo4j://statistics` - Graph statistics

**Connection**: Neo4j Python driver

#### Redis MCP Server

**Tools:**
- `list_keys(pattern: str)` - List keys matching pattern
- `get_key_type(key: str)` - Get type of key
- `execute_command(command: str)` - Execute Redis command
- `get_info()` - Get server info
- `validate_command(command: str)` - Validate command syntax
- `get_config()` - Get Redis configuration

**Resources:**
- `redis://info` - Server information
- `redis://config` - Configuration
- `redis://stats` - Statistics

**Connection**: redis-py

#### HBase MCP Server

**Tools:**
- `list_tables()` - List all tables
- `describe_table(table: str)` - Get table schema
- `scan_table(table: str, limit: int)` - Scan table rows
- `execute_query(table: str, query: str)` - Execute HBase query
- `validate_query(table: str, query: str)` - Validate query
- `get_column_families(table: str)` - Get column families

**Resources:**
- `hbase://{table}/schema` - Table schema
- `hbase://{table}/families` - Column families
- `hbase://tables` - All tables

**Connection**: HappyBase (HBase Python client)

#### RDF MCP Server

**Tools:**
- `list_graphs()` - List all named graphs
- `run_sparql(query: str)` - Execute SPARQL query
- `validate_sparql(query: str)` - Validate SPARQL syntax
- `get_ontology()` - Get ontology/schema information
- `explain_sparql(query: str)` - Explain query execution

**Resources:**
- `rdf://graphs` - Named graphs
- `rdf://ontology` - Ontology information
- `rdf://prefixes` - Common prefixes

**Connection**: rdflib or SPARQLWrapper

## Technology Stack

### Core Technologies
- **Language**: Python 3.10+
- **LLM**: Groq API 
- **MCP Framework**: FastMCP (Python) or MCP SDK (if using TypeScript)
- **Async Framework**: asyncio

### Database Drivers
- **MongoDB**: pymongo
- **Neo4j**: neo4j (official Python driver)
- **Redis**: redis-py
- **HBase**: happybase
- **RDF**: rdflib, SPARQLWrapper

### Frontend (Optional)
- **Streamlit** (rapid prototyping) or **React** (production-ready)

### Additional Libraries
- **pydantic**: Data validation
- **python-dotenv**: Configuration management
- **pytest**: Testing
- **asyncio**: Async operations

## Project Structure

```
llm-nosql-project/
├── docs/
│   ├── PROJECT_OVERVIEW.md       # This file
│   ├── TODO.md                   # Task tracking
│   ├── literature_review.md      # Research findings
│   └── architecture.md           # Detailed architecture
├── src/
│   ├── main_app/
│   │   ├── __init__.py
│   │   ├── app.py               # Main application entry
│   │   ├── query_engine.py      # LLM query translation logic
│   │   ├── mcp_manager.py       # MCP client manager
│   │   └── cross_db_compare.py  # Cross-database comparison
│   ├── mcp_servers/
│   │   ├── mongodb_mcp/
│   │   │   ├── __init__.py
│   │   │   ├── server.py        # MongoDB MCP server
│   │   │   └── tools.py         # MongoDB tools
│   │   ├── neo4j_mcp/
│   │   │   ├── __init__.py
│   │   │   ├── server.py        # Neo4j MCP server
│   │   │   └── tools.py         # Neo4j tools
│   │   ├── redis_mcp/
│   │   │   ├── __init__.py
│   │   │   ├── server.py        # Redis MCP server
│   │   │   └── tools.py         # Redis tools
│   │   ├── hbase_mcp/
│   │   │   ├── __init__.py
│   │   │   ├── server.py        # HBase MCP server
│   │   │   └── tools.py         # HBase tools
│   │   └── rdf_mcp/
│   │       ├── __init__.py
│   │       ├── server.py        # RDF MCP server
│   │       └── tools.py         # RDF tools
│   └── utils/
│       ├── __init__.py
│       ├── config.py            # Configuration
│       └── logger.py            # Logging utilities
├── tests/
│   ├── test_mongodb_mcp.py
│   ├── test_neo4j_mcp.py
│   ├── test_query_engine.py
│   └── test_integration.py
├── datasets/
│   ├── mongodb_samples/         # Sample MongoDB data
│   ├── neo4j_samples/           # Sample Neo4j data
│   ├── redis_samples/           # Sample Redis data
│   └── test_queries.json        # Test natural language queries
├── evaluation/
│   ├── benchmark.py             # Benchmarking script
│   ├── results/                 # Evaluation results
│   └── metrics.py               # Evaluation metrics
├── frontend/                    # Optional UI
│   └── streamlit_app.py
├── requirements.txt
├── .env.example
├── README.md
└── pyproject.toml
```

## Implementation Phases

### Phase 1: Literature Review & Setup (Week 1)
- Read 3-4 research papers on text-to-NoSQL translation
- Document findings in `literature_review.md`
- Set up development environment
- Install database systems (Docker recommended)

### Phase 2: MongoDB MCP Server (Week 2)
- Implement MongoDB MCP server with all tools
- Test schema extraction and query execution
- Validate query generation

### Phase 3: Main Application & Query Engine (Week 2-3)
- Build MCP client manager
- Implement LLM-based query translation
- Create basic CLI interface

### Phase 4: Neo4j MCP Server (Week 3)
- Implement Neo4j MCP server
- Add graph-specific tools and resources
- Test Cypher query generation

### Phase 5: Additional Database Servers (Week 4)
- Implement Redis MCP server
- Implement HBase MCP server
- Implement RDF MCP server

### Phase 6: Cross-Database Comparison (Week 5)
- Build comparison module
- Test same query across all databases
- Generate comparison reports

### Phase 7: Validation & Testing (Week 5-6)
- Comprehensive testing with diverse queries
- Benchmark against existing solutions
- User testing (if possible)

### Phase 8: Documentation & Presentation (Week 6-7)
- Write final report
- Prepare demo presentation
- Create video demonstration

## Key Features

### 1. Schema Exploration
- Users can ask: "What collections are in the database?"
- System uses MCP resources to provide schema information
- LLM uses this context for better query generation

### 2. Query Translation
Example flow:
```
User: "Find all users who live in New York and are over 25"

System:
1. Calls MongoDB MCP: get_collection_schema("mydb", "users")
2. LLM generates: {"city": "New York", "age": {"$gt": 25}}
3. Calls MongoDB MCP: execute_query("mydb", "users", query)
4. Returns results with explanation
```

### 3. Query Validation
- Before executing, validate query syntax
- Check if query fields exist in schema
- Provide suggestions for corrections

### 4. Query Explanation
- Explain what the query does in natural language
- Show how it maps to database schema
- Highlight potential optimizations

### 5. Cross-Database Comparison
Same natural language query → Multiple database queries:
```
Natural Language: "Find all products with price > 100"

MongoDB: db.products.find({"price": {"$gt": 100}})
Neo4j: MATCH (p:Product) WHERE p.price > 100 RETURN p
Redis: (Custom logic with SCAN and GET)
```

## Evaluation Metrics

1. **Query Accuracy**
   - Percentage of queries that execute successfully
   - Percentage of queries that return correct results

2. **Semantic Correctness**
   - Do results match expected answers?
   - Human evaluation on sample queries

3. **Usability**
   - User study: How easy is it for non-experts?
   - Time to complete tasks

4. **Cross-Database Consistency**
   - Do equivalent queries return similar results?

## Research Contribution

- Novel use of MCP for multi-database systems
- Comparison of LLM performance across different NoSQL types
- Benchmark dataset for text-to-NoSQL translation
- Open-source MCP servers for each database type

## References

1. Zhiqian Qin et al. (2025). "MultiTEND: A Multilingual Benchmark for Natural Language to NoSQL Query Translation." ACL.

2. Lu, Jinwei, et al. (2025). "Bridging the gap: Enabling natural language queries for nosql databases through text-to-nosql translation." arXiv.

3. Tola, Alessandro (2024). "Towards user-friendly nosql: A synthetic dataset approach and large language models for natural language query translation." Politecnico di Torino.

4. Yang, Tianhao (2025). "LLM-Enhanced Data Management in Multi-Model Databases."

## Team Information

- **Team Size**: 4-5 students
- **Presentation**: Last session of the course
- **Deliverables**:
  - Working system with MCP servers
  - Experiment report
  - Literature review
  - Final presentation/demo

## Getting Started

1. Clone the repository
2. Set up Python virtual environment
3. Install dependencies: `pip install -r requirements.txt`
4. Set up databases (Docker Compose recommended)
5. Configure API keys in `.env`
6. Start with MongoDB MCP server
7. Follow TODO.md for step-by-step implementation

## Important Notes

- Start with 2 databases (MongoDB + Neo4j) before expanding
- Test incrementally - don't build everything at once
- Use version control (Git) with frequent commits
- Document design decisions and challenges
- Keep track of research findings
- Regular team meetings to sync progress

## Success Criteria

✅ Successfully translate natural language to queries for 3+ database types
✅ Schema exploration working for all supported databases
✅ Query validation with meaningful error messages
✅ Cross-database comparison implemented
✅ Literature review completed with 3+ papers
✅ Working demo with real-world examples
✅ Comprehensive documentation
✅ Evaluation with benchmark queries
